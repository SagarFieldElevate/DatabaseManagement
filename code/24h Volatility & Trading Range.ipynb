{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycoingecko import CoinGeckoAPI\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import os\n",
    "from data_upload_utils import upload_to_github, update_airtable, create_airtable_record, delete_file_from_github\n",
    "\n",
    "# Initialize CoinGecko\n",
    "cg = CoinGeckoAPI()\n",
    "\n",
    "# Define coins\n",
    "coins = {\n",
    "    'BTC': 'bitcoin',\n",
    "    'ETH': 'ethereum',\n",
    "    'ADA': 'cardano',\n",
    "    'SOL': 'solana',\n",
    "    'DOT': 'polkadot',\n",
    "    'AVAX': 'avalanche-2'\n",
    "}\n",
    "\n",
    "# Fetch 365 days of OHLC data and compute metrics\n",
    "data = []\n",
    "for symbol, coin_id in coins.items():\n",
    "    market_data = cg.get_coin_market_chart_by_id(id=coin_id, vs_currency='usd', days=365)\n",
    "    ohlc_data = market_data['prices']\n",
    "    \n",
    "    for i in range(1, len(ohlc_data)):\n",
    "        # Extract previous day's OHLC data and current day OHLC data\n",
    "        prev_day = ohlc_data[i-1]\n",
    "        current_day = ohlc_data[i]\n",
    "        \n",
    "        prev_timestamp, prev_price = prev_day\n",
    "        current_timestamp, current_price = current_day\n",
    "        \n",
    "        # Calculate High, Low, Volatility, Trading Range\n",
    "        high = max(prev_price, current_price)  # Max of the two days\n",
    "        low = min(prev_price, current_price)   # Min of the two days\n",
    "        \n",
    "        volatility = ((high - low) / low) * 100 if low > 0 else 0\n",
    "        trading_range = high - low\n",
    "        \n",
    "        # Store data\n",
    "        data.append({\n",
    "            'symbol': symbol,\n",
    "            'timestamp': datetime.utcfromtimestamp(current_timestamp / 1000),  # Convert timestamp\n",
    "            'high_24h_usd': high,\n",
    "            'low_24h_usd': low,\n",
    "            'volatility_24h_%': round(volatility, 2),\n",
    "            'trading_range_24h_usd': round(trading_range, 2)\n",
    "        })\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Excel export\n",
    "timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "filename = f\"historical_volatility_trading_range_365_days_{timestamp}.xlsx\"\n",
    "df.to_excel(filename, index=False)\n",
    "\n",
    "# GitHub + Airtable Upload\n",
    "AIRTABLE_API_KEY = os.getenv(\"AIRTABLE_API_KEY\")\n",
    "BASE_ID = \"appnssPRD9yeYJJe5\"\n",
    "TABLE_NAME = \"Database\"\n",
    "airtable_url = f\"https://api.airtable.com/v0/{BASE_ID}/{TABLE_NAME}\"\n",
    "airtable_headers = {\n",
    "    \"Authorization\": f\"Bearer {AIRTABLE_API_KEY}\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "response = requests.get(airtable_url, headers=airtable_headers)\n",
    "response.raise_for_status()\n",
    "data_airtable = response.json()\n",
    "\n",
    "# Check for existing file\n",
    "existing_records = [\n",
    "    rec for rec in data_airtable['records']\n",
    "    if rec['fields'].get('Name') == \"365-Day Volatility and Range\"\n",
    "]\n",
    "\n",
    "if existing_records and 'Database Attachment' in existing_records[0]['fields']:\n",
    "    record_id = existing_records[0]['id']\n",
    "    existing_data = existing_records[0]['fields'].get('Data', [])\n",
    "else:\n",
    "    record_id = None\n",
    "    existing_data = []\n",
    "\n",
    "# Convert datetime objects to strings (ISO 8601 format) for both new and existing data\n",
    "for entry in data:\n",
    "    entry['timestamp'] = entry['timestamp'].isoformat()  # Convert datetime to ISO string\n",
    "\n",
    "# If appending new data to existing data\n",
    "new_data_to_append = data  # In this case, it's the same as the current data, but you could compare with the previous set if needed\n",
    "existing_data.extend(new_data_to_append)\n",
    "\n",
    "# Prepare Airtable update\n",
    "if record_id:\n",
    "    patch_url = f\"{airtable_url}/{record_id}\"\n",
    "    patch_payload = {\n",
    "        \"fields\": {\n",
    "            \"Name\": \"365-Day Volatility and Range\",\n",
    "            \"Data\": existing_data  # Append new data to existing data\n",
    "        }\n",
    "    }\n",
    "    airtable_resp = requests.patch(patch_url, headers=airtable_headers, json=patch_payload)\n",
    "else:\n",
    "    post_payload = {\n",
    "        \"records\": [{\n",
    "            \"fields\": {\n",
    "                \"Name\": \"365-Day Volatility and Range\",\n",
    "                \"Data\": existing_data  # Append new data to existing data\n",
    "            }\n",
    "        }]\n",
    "    }\n",
    "    airtable_resp = requests.post(airtable_url, headers=airtable_headers, json=post_payload)\n",
    "\n",
    "if airtable_resp.status_code == 200:\n",
    "    print(\"‚úÖ Successfully updated Airtable record with new data.\")\n",
    "else:\n",
    "    raise Exception(f\"‚ùå Airtable update failed: {airtable_resp.status_code} - {airtable_resp.text}\")\n",
    "\n",
    "# Upload to GitHub\n",
    "GITHUB_REPO = \"SagarFieldElevate/DatabaseManagement\"\n",
    "BRANCH = \"main\"\n",
    "UPLOAD_PATH = \"uploads\"\n",
    "GITHUB_TOKEN = os.getenv(\"GH_TOKEN\")\n",
    "\n",
    "# Use common function to upload file to GitHub\n",
    "github_response = upload_to_github(filename, GITHUB_REPO, BRANCH, UPLOAD_PATH, GITHUB_TOKEN)\n",
    "raw_url = github_response['content']['download_url']  # Get the raw URL from GitHub response\n",
    "file_sha = github_response['content']['sha']  # Get the SHA for file deletion later\n",
    "\n",
    "# Update Airtable with GitHub URL\n",
    "if record_id:\n",
    "    patch_url = f\"{airtable_url}/{record_id}\"\n",
    "    patch_payload = {\n",
    "        \"fields\": {\n",
    "            \"Database Attachment\": [{\n",
    "                \"url\": raw_url,\n",
    "                \"filename\": filename\n",
    "            }]\n",
    "        }\n",
    "    }\n",
    "    airtable_resp = requests.patch(patch_url, headers=airtable_headers, json=patch_payload)\n",
    "else:\n",
    "    post_payload = {\n",
    "        \"records\": [{\n",
    "            \"fields\": {\n",
    "                \"Name\": \"365-Day Volatility and Range\",\n",
    "                \"Database Attachment\": [{\n",
    "                    \"url\": raw_url,\n",
    "                    \"filename\": filename\n",
    "                }]\n",
    "            }\n",
    "        }]\n",
    "    }\n",
    "    airtable_resp = requests.post(airtable_url, headers=airtable_headers, json=post_payload)\n",
    "\n",
    "if airtable_resp.status_code != 200:\n",
    "    raise Exception(f\"‚ùå Airtable upload failed: {airtable_resp.status_code} - {airtable_resp.text}\")\n",
    "\n",
    "# Delete the file from GitHub after upload\n",
    "delete_file_from_github(filename, GITHUB_REPO, BRANCH, UPLOAD_PATH, GITHUB_TOKEN, file_sha)\n",
    "\n",
    "# Delete local file\n",
    "os.remove(filename)\n",
    "print(\"üßΩ Local file and GitHub file deleted.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
