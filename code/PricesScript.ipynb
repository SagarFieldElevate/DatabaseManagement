{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycoingecko import CoinGeckoAPI\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import os\n",
    "import base64\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "# Initialize API\n",
    "cg = CoinGeckoAPI()\n",
    "\n",
    "# List of coins and their CoinGeeko IDs\n",
    "coins = {\n",
    "    'BTC': 'bitcoin',\n",
    "    'ETH': 'ethereum',\n",
    "    'ADA': 'cardano',\n",
    "    'SOL': 'solana',\n",
    "    'DOT': 'polkadot',\n",
    "    'AVAX': 'avalanche-2'\n",
    "}\n",
    "\n",
    "# Function to fetch OHLC data for the last 365 days (daily granularity)\n",
    "def fetch_ohlc(coin_id):\n",
    "    ohlc = cg.get_coin_ohlc_by_id(id=coin_id, vs_currency='usd', days=365)\n",
    "    df = pd.DataFrame(ohlc, columns=['timestamp', 'open', 'high', 'low', 'close'])\n",
    "    df['date'] = pd.to_datetime(df['timestamp'], unit='ms').dt.date\n",
    "    df.drop(columns=['timestamp'], inplace=True)\n",
    "    return df\n",
    "\n",
    "# Fetch new OHLC data\n",
    "ohlc_data = {}\n",
    "for symbol, coin_id in coins.items():\n",
    "    df = fetch_ohlc(coin_id)\n",
    "    df['symbol'] = symbol\n",
    "    ohlc_data[symbol] = df\n",
    "\n",
    "# Combine new data into one DataFrame\n",
    "new_data_df = pd.concat(ohlc_data.values(), ignore_index=True)\n",
    "\n",
    "# Fetch the current attachment URL from Airtable (replace with your Airtable API calls)\n",
    "AIRTABLE_API_KEY = os.getenv(\"AIRTABLE_API_KEY\")\n",
    "BASE_ID = \"appnssPRD9yeYJJe5\"\n",
    "TABLE_NAME = \"Database\"\n",
    "airtable_url = f\"https://api.airtable.com/v0/{BASE_ID}/{TABLE_NAME}\"\n",
    "\n",
    "airtable_headers = {\n",
    "    \"Authorization\": f\"Bearer {AIRTABLE_API_KEY}\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "# Fetch records from Airtable\n",
    "response = requests.get(airtable_url, headers=airtable_headers)\n",
    "response.raise_for_status()\n",
    "data = response.json()\n",
    "\n",
    "\n",
    "# Check if there's an existing attachment\n",
    "if data['records']:\n",
    "    # Assuming the first record has the attachment we need\n",
    "    record = data['records'][0].get('fields', {})\n",
    "    attachment_field = record.get('Database Attachment', [])\n",
    "\n",
    "    if attachment_field:\n",
    "        attachment_url = attachment_field[0].get('url')\n",
    "\n",
    "        if attachment_url:\n",
    "            # Download the existing file from the attachment URL\n",
    "            existing_file = requests.get(attachment_url)\n",
    "            existing_file.raise_for_status()\n",
    "\n",
    "            # Assume the existing file is Excel format (you can adapt this if it's in CSV)\n",
    "            existing_df = pd.read_excel(BytesIO(existing_file.content))\n",
    "\n",
    "            # Append the new data to the existing data\n",
    "            combined_df = pd.concat([existing_df, new_data_df], ignore_index=True)\n",
    "        else:\n",
    "            # No attachment URL found, create a new file\n",
    "            combined_df = new_data_df\n",
    "    else:\n",
    "        # No 'Database Attachment' field in the first record, create a new file\n",
    "        combined_df = new_data_df\n",
    "else:\n",
    "    # No records in Airtable, create a new file\n",
    "    combined_df = new_data_df\n",
    "\n",
    "# Save the updated data to a new Excel file\n",
    "timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "filename = f\"crypto_ohlc_365days_with_history_{timestamp}.xlsx\"\n",
    "combined_df.to_excel(filename, index=False)\n",
    "\n",
    "# Upload the updated file to GitHub\n",
    "GITHUB_REPO = \"SagarFieldElevate/DatabaseManagement\"\n",
    "BRANCH = \"main\"\n",
    "UPLOAD_PATH = \"uploads\"\n",
    "GITHUB_TOKEN = os.getenv(\"GH_TOKEN\")\n",
    "\n",
    "with open(filename, \"rb\") as f:\n",
    "    content = base64.b64encode(f.read()).decode()\n",
    "\n",
    "upload_url = f\"https://api.github.com/repos/{GITHUB_REPO}/contents/{UPLOAD_PATH}/{filename}\"\n",
    "upload_payload = {\n",
    "    \"message\": f\"Upload OHLC data with history {timestamp}\",\n",
    "    \"content\": content,\n",
    "    \"branch\": BRANCH\n",
    "}\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {GITHUB_TOKEN}\",\n",
    "    \"Accept\": \"application/vnd.github+json\"\n",
    "}\n",
    "upload_resp = requests.put(upload_url, headers=headers, json=upload_payload)\n",
    "if upload_resp.status_code not in [200, 201]:\n",
    "    raise Exception(f\"‚ùå GitHub upload failed: {upload_resp.status_code} - {upload_resp.text}\")\n",
    "\n",
    "file_sha = upload_resp.json()[\"content\"][\"sha\"]\n",
    "raw_url = f\"https://raw.githubusercontent.com/{GITHUB_REPO}/{BRANCH}/{UPLOAD_PATH}/{filename}\"\n",
    "\n",
    "# Try to find the existing record (assuming we use \"Name\" = \"OHLC Master Data with History\")\n",
    "existing_records = [rec for rec in data['records'] if rec['fields'].get('Name') == \"OHLC Master Data with History\"]\n",
    "\n",
    "if existing_records:\n",
    "    # üõ† Update existing record using PATCH\n",
    "    record_id = existing_records[0]['id']\n",
    "    patch_url = f\"{airtable_url}/{record_id}\"\n",
    "    patch_payload = {\n",
    "        \"fields\": {\n",
    "            \"Database Attachment\": [{\n",
    "                \"url\": raw_url,\n",
    "                \"filename\": filename\n",
    "            }]\n",
    "        }\n",
    "    }\n",
    "    airtable_resp = requests.patch(patch_url, headers=airtable_headers, json=patch_payload)\n",
    "else:\n",
    "    # üÜï If not found, create new record\n",
    "    post_payload = {\n",
    "        \"records\": [{\n",
    "            \"fields\": {\n",
    "                \"Name\": \"OHLC Master Data with History\",\n",
    "                \"Database Attachment\": [{\n",
    "                    \"url\": raw_url,\n",
    "                    \"filename\": filename\n",
    "                }]\n",
    "            }\n",
    "        }]\n",
    "    }\n",
    "    airtable_resp = requests.post(airtable_url, headers=airtable_headers, json=post_payload)\n",
    "\n",
    "if airtable_resp.status_code != 200:\n",
    "    raise Exception(f\"‚ùå Airtable upload failed: {airtable_resp.status_code} - {airtable_resp.text}\")\n",
    "\n",
    "# Delete the file from GitHub after upload\n",
    "delete_url = f\"https://api.github.com/repos/{GITHUB_REPO}/contents/{UPLOAD_PATH}/{filename}\"\n",
    "file_sha = upload_resp.json()['content']['sha']  # Get the SHA of the uploaded file\n",
    "delete_payload = {\n",
    "    \"message\": f\"Delete 365-day volatility and trading range file {timestamp}\",\n",
    "    \"sha\": file_sha\n",
    "}\n",
    "\n",
    "delete_resp = requests.delete(delete_url, headers=headers, json=delete_payload)\n",
    "if delete_resp.status_code != 200:\n",
    "    raise Exception(f\"‚ùå GitHub file deletion failed: {delete_resp.status_code} - {delete_resp.text}\")\n",
    "\n",
    "# Delete local file\n",
    "os.remove(filename)\n",
    "print(\"üßΩ Local file and GitHub file deleted.\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
